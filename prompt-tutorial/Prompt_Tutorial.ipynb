{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0d24652-75aa-40b2-bbcb-cbb2e8f41c10",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "Install togeher AI for a low cost open source way to validate GenAI prompts.\n",
    "\n",
    "## Important\n",
    "You will need to obtain an API key from the Together AI [quickstart](https://docs.together.ai/docs/quickstart) and copy that key into the TOGETHER_API_KEY variable below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d701c3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install together==1.5.21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50225cc3-83d3-4259-8eb3-f2c88d16f0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOGETHER_API_KEY=\"insert_key_here\"\n",
    "\n",
    "from together import Together\n",
    "\n",
    "def send_prompt(messages: []):\n",
    "    client = Together(api_key=TOGETHER_API_KEY)\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\",\n",
    "        messages=messages,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def create_prompt(prompt: str):\n",
    "    return [{\"role\": \"user\", \"content\": prompt}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156f7c07-d923-41e6-84e3-805829638fbf",
   "metadata": {},
   "source": [
    "# Zero-Shot Learning\n",
    "\n",
    "**What** \n",
    "\n",
    "Providing a prompt without any prior examples or contextual information. The model relies solely on its pre-trained knowledge to generate a response.\n",
    "\n",
    "**Why/When** \n",
    "\n",
    "- When you want a general or unbiased response.\n",
    "\n",
    "- Suitable for open-ended questions or tasks where specific formatting or behavior is not required.\n",
    "\n",
    "- Useful when testing the model's general understanding of a topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4e5c0e-f18c-412e-9905-0229c962bee4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Zero-Shot\n",
    "zero_shot_prompt = \"\"\"\n",
    "    Explain what a large language model prompt is.\"\"\"\n",
    "\n",
    "prompt = create_prompt(zero_shot_prompt)\n",
    "\n",
    "print(send_prompt(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8fea36-7c6b-4158-932a-75297aa72d70",
   "metadata": {},
   "source": [
    "# One-Shot Learning\n",
    "\n",
    "**What**\n",
    "\n",
    "Providing a single example alongside the prompt to help the model understand the desired context, structure, or output format.\n",
    "\n",
    "**Why/When**\n",
    "\n",
    "- When the task is moderately complex or ambiguous.\n",
    "\n",
    "- Useful if you want the model to mimic a specific pattern or response style.\n",
    "\n",
    "- Helpful when limited examples are available, but you still want to steer the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfc8ccf-cc18-4d97-af11-d266fc893457",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "one_shot_prompt = \"\"\"\n",
    "    Zero shot prompting is considered a beginner level for prompt engineering.\n",
    "    What level would LLM fine tuning be considered?\"\"\"\n",
    "\n",
    "prompt = create_prompt(one_shot_prompt)\n",
    "\n",
    "print(send_prompt(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e371dde-0e1d-4b97-85ba-b39a6d3486da",
   "metadata": {},
   "source": [
    "# Few-Shot Learning\n",
    "\n",
    "**What**\n",
    "\n",
    "Providing multiple examples (typically 2–5) along with the prompt to help the model better understand the desired format, tone, or reasoning process.\n",
    "\n",
    "**Why/When**\n",
    "\n",
    "- When a specific or structured output is needed.\n",
    "\n",
    "- Ideal when you have several high-quality examples that demonstrate the desired behavior.\n",
    "\n",
    "- Helps guide the model to be more consistent and accurate in its response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b26ce1-5e8f-4cc6-b460-573414b35227",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "few_shot_prompt = \"\"\"\n",
    "    The food was good! | Positive\n",
    "    The service was slow. | Negative\n",
    "    The selection was good but the quality low. | Neutral\n",
    "    The atmosphere was great! \"\"\"\n",
    "\n",
    "prompt = create_prompt(few_shot_prompt)\n",
    "\n",
    "print(send_prompt(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a88d62b",
   "metadata": {},
   "source": [
    "# Directional stimulus prompt\n",
    "\n",
    "**What**\n",
    "\n",
    "Providing the AI with a subtle hint or clue in the prompt to steer it toward the desired type of response without giving a full example.\n",
    "\n",
    "**Why/When**\n",
    "\n",
    "- When you want to influence the AI’s focus or style but maintain flexibility in its answer.\n",
    "\n",
    "- Useful when a full example isn’t needed or available, but some guidance improves relevance or accuracy.\n",
    "\n",
    "- Helps nudge the model without over-constraining it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7972487d",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_stimulus_prompt = \"\"\"\n",
    "    List 3 successful and 3 unsuccessful prompts with clear examples, \n",
    "    followed by a bullet-point explanation of the techniques used in each.\n",
    "    Use a formal, educational tone.\n",
    "    \"\"\"\n",
    "\n",
    "prompt = create_prompt(directional_stimulus_prompt)\n",
    "\n",
    "print(send_prompt(prompt))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8119b36",
   "metadata": {},
   "source": [
    "# Instruction Prompting: \n",
    "\n",
    "**What**\n",
    "\n",
    "Embedding explicit steps or instructions directly within the prompt to guide the model’s response.\n",
    "\n",
    "**Why/When**\n",
    "\n",
    "- When the task has clearly defined steps that reliably produce the desired outcome.\n",
    "\n",
    "- Ideal for procedural tasks, formatting requirements, or when consistency and control are important.\n",
    "\n",
    "- Helps reduce ambiguity in the model's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c5dc59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Instruction_prompt = \"\"\"\n",
    "    Read the following wikipedia article. Do not change any of the text in the article. remove the [1], [2], [3] from the article.\n",
    "\n",
    "    The largest and most capable LLMs are generative pretrained transformers (GPTs), which are largely used in generative chatbots such as ChatGPT, Gemini or Claude. \n",
    "    LLMs can be fine-tuned for specific tasks or guided by prompt engineering.[1] These models acquire predictive power regarding syntax, semantics, and ontologies[2] \n",
    "    inherent in human language corpora, but they also inherit inaccuracies and biases present in the data they are trained in.[3]?\"\"\"\n",
    "\n",
    "prompt = create_prompt(Instruction_prompt)\n",
    "\n",
    "print(send_prompt(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d823842-9d7e-421f-ab80-b05622329311",
   "metadata": {},
   "source": [
    "# Role-Based Prompting\n",
    "\n",
    "**What**\n",
    "\n",
    "Assigning a specific role, persona, or point of view for the AI to adopt when generating a response.\n",
    "\n",
    "**Why/When**\n",
    "\n",
    "- When you want the AI to behave in a particular way (e.g., as a teacher, lawyer, or software engineer).\n",
    "\n",
    "- Useful for setting tone, voice, or expertise level in responses.\n",
    "\n",
    "- Helps contextualize the prompt to match a specific audience or use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62dea4a-20a9-4abc-8ab0-2ce9ddc5936b",
   "metadata": {},
   "outputs": [],
   "source": [
    "role_based_prompt = \"\"\"\n",
    "    You are a prompt engineer.\n",
    "    Describe why prompt engineering is important.\"\"\"\n",
    "\n",
    "prompt = create_prompt(role_based_prompt)\n",
    "\n",
    "print(send_prompt(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ca98db-a30a-420c-bc6a-f98debc8f132",
   "metadata": {},
   "source": [
    "# Chain-of-Thought Prompting\n",
    "\n",
    "**What**\n",
    "\n",
    "Encouraging the AI to show its reasoning by breaking down the steps it takes to reach a conclusion.\n",
    "\n",
    "**Why/When**\n",
    "\n",
    "- When the task involves reasoning, logic, or multiple steps.\n",
    "\n",
    "- Useful for complex questions where seeing intermediate steps improves accuracy and transparency.\n",
    "\n",
    "- Helps debug or refine prompts by making the model's thought process visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8512f005-eea3-4cae-8603-92b17d0c9bcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chain_of_thought_prompt = \"\"\"\n",
    "    Describe the process of fine tuning a Foundation Model.\n",
    "    List each step and why you came to that conclusion.\"\"\"\n",
    "\n",
    "prompt = create_prompt(chain_of_thought_prompt)\n",
    "\n",
    "print(send_prompt(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192869f3-a0ee-4d12-ad4a-a5ccb66f32b2",
   "metadata": {},
   "source": [
    "# Iterative Prompting\n",
    "\n",
    "**What**\n",
    "\n",
    "Using the chat history to progressively refine prompts and guide the AI toward the desired response through multiple interactions.\n",
    "\n",
    "**Why/When**\n",
    "\n",
    "- When the task is complex, ambiguous, or requires fine-tuning.\n",
    "\n",
    "- Useful for refining outputs through follow-up questions, clarifications, or corrections.\n",
    "\n",
    "- Ideal when the initial response is close but not quite right, and improvement is needed through back-and-forth dialogue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31966f18-4146-4343-ad0c-f2597b727e97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Store previous messages for better context\n",
    "messages = []\n",
    "iterative_prompt = \"\"\"\n",
    "    What is Low-Rank Adaptation?\"\"\"\n",
    "\n",
    "messages += create_prompt(iterative_prompt)\n",
    "\n",
    "first_response = send_prompt(messages)\n",
    "print(first_response)\n",
    "\n",
    "messages.append({\"role\": \"assistant\",\"content\":first_response})\n",
    "\n",
    "refined_prompt = \"\"\"\n",
    "    Give me a concise summary.\"\"\"\n",
    "\n",
    "messages += create_prompt(refined_prompt)\n",
    "print(\"\\n\\n----------------------------------------------------------\\nRefined Reponse \\n\\n\")\n",
    "print(send_prompt(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23de2f0d-5112-4fc8-9124-7915820a58e9",
   "metadata": {},
   "source": [
    "# Prompt Chaining\n",
    "\n",
    "**What**\n",
    "\n",
    "Breaking down a complex task into smaller, manageable prompts that are executed sequentially, where each step uses the previous context.\n",
    "\n",
    "**Why/When**\n",
    "\n",
    "- When solving a complex problem that benefits from stepwise processing.\n",
    "\n",
    "- Useful for tasks requiring intermediate results or iterative refinement.\n",
    "\n",
    "- Helps maintain clarity and control over multi-step workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c1d162-5b7a-475e-939d-9fb04217e5e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "messages = []\n",
    "chaining_prompt  = \"\"\"\n",
    "    List 5 companies with Foundation models.\"\"\"\n",
    "\n",
    "messages += create_prompt(chaining_prompt)\n",
    "\n",
    "first_response = send_prompt(messages)\n",
    "print(first_response)\n",
    "\n",
    "messages.append({\"role\": \"assistant\",\"content\":first_response})\n",
    "\n",
    "chaining_content_prompt = \"\"\"\n",
    "    Choose one of the companies and describe the benefits of their foundation model.\"\"\"\n",
    "\n",
    "messages += create_prompt(chaining_content_prompt)\n",
    "print(\"\\n\\n----------------------------------------------------------\\nChain Response \\n\\n\")\n",
    "print(send_prompt(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2977162e-2acc-467b-9046-210e765cd1cf",
   "metadata": {},
   "source": [
    "# Negative Prompting\n",
    "\n",
    "**What**\n",
    "\n",
    "Providing constraints within the prompt to tell the AI what to avoid in its response.\n",
    "\n",
    "**Why/When**\n",
    "\n",
    "- When certain types of answers, formats, or content must be excluded.\n",
    "\n",
    "- Useful for ensuring accuracy, avoiding hallucinations, or staying within system or business rules.\n",
    "\n",
    "- Helps prevent the model from making incorrect assumptions or including irrelevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3c3dff-ec87-43e7-8d9b-3865fadfea03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "negative_prompt = \"\"\"\n",
    "    Give me the top five LLM fine tuning methods that do not include LoRA\"\"\"\n",
    "\n",
    "prompt = create_prompt(negative_prompt)\n",
    "\n",
    "print(send_prompt(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29db43ba-8586-4862-9d3a-38167f0c53d0",
   "metadata": {},
   "source": [
    "# Hybrid Prompting\n",
    "\n",
    "**What**\n",
    "\n",
    "Combining multiple prompting techniques to provide more comprehensive guidance to the AI.\n",
    "\n",
    "**Why/When**\n",
    "\n",
    "- When the request is complex or has multiple constraints.\n",
    "\n",
    "- Useful when output requires specific structure, behavior, or reasoning.\n",
    "\n",
    "- A powerful strategy for building large or production-grade prompts that demand precision and flexibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3195b917-48e2-414d-beba-cb6adf29ac2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# one shot -> chain-of-thought\n",
    "hybrid_prompt = \"\"\"\n",
    "    LoRA reduces the resource cost of fine tuning a model.\n",
    "    Descibe step-by-step how you can further optimize LoRA.\"\"\"\n",
    "\n",
    "prompt = create_prompt(hybrid_prompt)\n",
    "\n",
    "print(send_prompt(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba19db2e",
   "metadata": {},
   "source": [
    "# Tree of thought / Self-Consistency\n",
    "\n",
    "**What**\n",
    "\n",
    "Breaking down a task into multiple reasoning paths or steps, generating several possible solutions or “thought branches,” then selecting the best or most consistent answer before proceeding.\n",
    "\n",
    "**Why/When**\n",
    "\n",
    "- When facing complex problems that can be solved through multiple approaches.\n",
    "\n",
    "- Useful for improving answer accuracy by comparing alternatives and choosing the best.\n",
    "\n",
    "- Helps reduce errors by validating or cross-checking different reasoning paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f20b851-7a95-49d5-b70a-6099e65960af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tree_of_thought_prompt = \"\"\"\n",
    "    Imagine three different experts are answering this question. \n",
    "    All experts will write down 1 step of their thinking, then share it with the group. \n",
    "    Then all experts will go on to the next step, etc. \n",
    "    If any expert realises they're wrong at any point then they leave. \n",
    "    The question is: \n",
    "    48 people are riding a bus. \n",
    "    On the first stop, 8 passengers get off, and 5 times as many people as the number who got off from the bus get into the bus. \n",
    "    On the second stop 21, passengers get off and 3 times fewer passengers get on. \n",
    "    How many passengers are riding the bus after the second stop?\"\"\"\n",
    "\n",
    "prompt = create_prompt(tree_of_thought_prompt)\n",
    "\n",
    "print(send_prompt(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a358bf0b",
   "metadata": {},
   "source": [
    "# Chain of density\n",
    "\n",
    "**What**\n",
    "\n",
    "Recursively summarizing content by creating an initial summary, then using prompts to review and refine it repeatedly until the summary captures all important points.\n",
    "\n",
    "**Why/When**\n",
    "\n",
    "- When you want to progressively condense large or complex text while ensuring completeness.\n",
    "\n",
    "- Particularly useful for summarizing documentation, reports, or lengthy articles.\n",
    "\n",
    "- Helps improve summary accuracy through iterative refinement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0890f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTICLE = \"\"\"\n",
    "A large language model (LLM) is a language model trained with self-supervised machine learning on a vast amount of text, designed for natural language processing tasks, especially language generation. \n",
    "    The largest and most capable LLMs are generative pretrained transformers (GPTs), which are largely used in generative chatbots such as ChatGPT, Gemini or Claude. LLMs can be fine-tuned for specific tasks or \n",
    "    guided by prompt engineering.[1] These models acquire predictive power regarding syntax, semantics, and ontologies[2] inherent in human language corpora, but they also inherit inaccuracies and biases present \n",
    "    in the data they are trained in.[3]\n",
    "    \"\"\"\n",
    "chain_of_density_prompt = f\"\"\"\n",
    "    Article: {ARTICLE}\n",
    "    You will generate increasingly concise, entity-dense summaries of the above Article.\n",
    "    Repeat the following 2 steps 5 times.\n",
    "    Step 1. Identify 1-3 informative Entities (\". \" delimited) from the Article which are missing from the previously generated summary.\n",
    "    Step 2. Write a new, denser summary of identical length which covers every entity and detail from the previous summary plus the Missing Entities.\n",
    "    A Missing Entity is:\n",
    "    - Relevant: to the main story.\n",
    "    - Specific: descriptive yet concise (5 words or fewer).\n",
    "    - Novel: not in the previous summary.\n",
    "    - Faithful: present in the Article.\n",
    "    - Anywhere: located anywhere in the Article.\n",
    "    Guidelines:\n",
    "    - The first summary should be long (4-5 sentences, ~80 words) yet highly non-specific, containing little information beyond the entities marked as missing. Use overly verbose language and fillers (e.g., \"this article discusses\") to reach ~80 words.\n",
    "    - Make every word count: rewrite the previous summary to improve flow and make space for additional entities.\n",
    "    - Make space with fusion, compression, and removal of uninformative phrases like \"the article discusses\".\n",
    "    - The summaries should become highly dense and concise yet self-contained, e.g., easily understood without the Article.\n",
    "    - Missing entities can appear anywhere in the new summary.\n",
    "    - Never drop entities from the previous summary. If space cannot be made, add fewer new entities.\n",
    "\n",
    "    Remember, use the exact same number of words for each summary.\n",
    "\n",
    "    Answer in JSON. The JSON should be a list (length 5) of dictionaries whose keys are \"Missing_Entities\" and \"Denser_Summary\".\n",
    "    \"\"\"\n",
    "\n",
    "prompt = [{\"role\": \"user\", \"content\": chain_of_density_prompt}]\n",
    "\n",
    "print(send_prompt(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de7ecd0-abad-450d-a90b-e56aae1b6efc",
   "metadata": {},
   "source": [
    "# ReAct Prompting (Reasoning + Acting)\n",
    "\n",
    "**What**\n",
    "\n",
    "Combining reasoning and actions in the prompt, where the AI alternates between thinking through a problem (reasoning) and taking explicit actions (like searching, querying, or calculating) before giving a final answer.\n",
    "\n",
    "**Why/When**\n",
    "\n",
    "- For complex tasks that require both logical reasoning and interaction with external knowledge or tools.\n",
    "\n",
    "- Helps improve accuracy by making the AI’s thought process and actions explicit.\n",
    "\n",
    "- Useful in scenarios like question answering, multi-step problem solving, or decision making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9778786d-93eb-436e-82bf-5be3967b84e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "react_prompt = \"\"\"\n",
    "    Let's think step-by-step and perform actions as needed:\n",
    "\n",
    "    Reasoning: The user reports that the model is generating repetitive responses. I need to analyze possible causes.\n",
    "    \n",
    "    Action: Check if the prompt has ambiguous instructions or lacks diversity in examples.\n",
    "    \n",
    "    Reasoning: The prompt is very short and doesn't specify varied output styles.\n",
    "    \n",
    "    Action: Suggest improving the prompt with more detailed instructions and diverse examples.\n",
    "    \n",
    "    Answer: The repetitive output is likely due to an underspecified prompt. Adding explicit diversity instructions and examples should improve response variety.\n",
    "    \"\"\"\n",
    "\n",
    "prompt = create_prompt(react_prompt)\n",
    "\n",
    "print(send_prompt(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6812c587-52eb-4c50-afd0-782e8f98e747",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "While this tutorial only scratches the surface of prompt engineering, it provides a solid foundation for anyone in their journey into Generative AI.\n",
    "\n",
    "New prompting techniques are emerging every day. In my experience, a Hybrid approach that combines Role-Based prompting to set the tone and Instructional prompting to define the process delivers the most consistent and reliable results in my daily tasks.\n",
    "\n",
    "As you explore and experiment, you'll develop your own combinations and preferences. The key is understanding the strengths of each style and applying them with intent.\n",
    "\n",
    "Happy prompting!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
